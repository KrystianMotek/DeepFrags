import argparse
import warnings
import os
import random

warnings.filterwarnings("ignore")
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

import tensorflow as tf
import numpy as np


class Output:
    def __init__(self, vector):
        self.vector = vector # row data generated by decoder 
        self.n = int((len(vector) - 3) / 3) # number of amino acids 

    @staticmethod
    def compute_dihedral(sin, cos):
        k = np.sqrt(np.square(sin) + np.square(cos))
        return np.degrees(np.arctan2(sin / k, cos / k))

    def displacement(self):
        return self.vector[0:3]
    
    def alpha(self):
        START = 3
        END = START + self.n
        return 180 * self.vector[START:END] # original alpha angles are normalized at the stage of data processing

    def sin_theta(self):
        START = 3 + self.n
        END = START + self.n
        return self.vector[START:END]
    
    def cos_theta(self):
        START = 3 + 2 * self.n
        END = START + self.n
        return self.vector[START:END]
    
    def theta(self):
        return self.compute_dihedral(self.sin_theta(), self.cos_theta())
    
    def to_original(self):
        angles = np.concatenate([[alpha, theta] for alpha, theta in zip(self.alpha(), self.theta())])
        return np.concatenate([self.displacement(), angles])


def one_hot_to_string(vector, codes):
    string = ""
    categories = len(codes)
    i = 0
    while i < len(vector):
        index = list(vector[i:i+categories]).index(1.0)
        string += codes[index]
        i += categories
    return string


def angles_distribution(ss, output: Output):
    # return plane and dihedral angles corresponding to secondary structure
    alpha = output.alpha()
    theta = output.theta()
    return [[ss, alpha, theta] for ss, alpha, theta in zip(ss, alpha, theta)]


def extract_ss(vector):
    # get secondary structure from label vector
    n = int(len(vector) / 23) 
    ORDINAL = 20 * n 
    return one_hot_to_string(vector[ORDINAL:], codes="HEC")


def hec_distribution(angles):
    h_angles = []
    e_angles = []
    c_angles = []
    for element in angles:
        ss = element[0]
        alpha = element[1]
        theta = element[2]
        if ss == "H": h_angles.append([alpha, theta])
        if ss == "E": h_angles.append([alpha, theta])
        if ss == "C": h_angles.append([alpha, theta])
    return h_angles, e_angles, c_angles


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-m", "--model", type=str, help="model to be used")
    parser.add_argument("-l", "--labels", type=str, help="sequences and secondary structures saved in a binary format")
    args = parser.parse_args()

    np.set_printoptions(formatter={"float": lambda x: "{0:0.2f}".format(x)})
    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

    model = args.model 
    model_name = os.path.splitext(os.path.basename(model))[0]
    labels = np.load(args.labels)

    # labels dimensionality
    observations = np.shape(labels)[0] 
    label_dim = np.shape(labels)[1] 

    label = tf.keras.layers.Input(shape=(label_dim,)) # define input layer

    # latent space processing
    latent_variables = np.load(f"{model}/latent.npy")
    latent_dim = np.shape(latent_variables)[2]
    mean, log_variance = latent_variables[0], latent_variables[1]
    z = np.concatenate([i + np.exp(0.5 * j) * np.random.normal(loc=0.0, scale=1.0, size=(1, latent_dim)) for i, j in zip(mean, log_variance)])

    latent_sample = np.array(random.sample(list(z), observations)) # sampling from the latent space

    # load decoder with trained parameters
    decoder = tf.keras.models.load_model(f"{model}/decoder.h5")
    decoder.load_weights(f"{model}/weights.h5", by_name=True, skip_mismatch=True)

    # reconstruct cooridnates 
    raw_output = decoder.predict(tf.keras.layers.concatenate([latent_sample, labels]))
    outputs = [Output(vector) for vector in raw_output]

    # get secondary structures from labels 
    ss = [extract_ss(vector) for vector in labels]

    # secondary structure with plane and dihedral angles
    angles = np.concatenate([angles_distribution(ss, output) for ss, output in zip(ss, outputs)]) 

    # divide angles into three categories
    h_angles, e_angles, c_angles = hec_distribution(angles)[0], hec_distribution(angles)[1], hec_distribution(angles)[2]
